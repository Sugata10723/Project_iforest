\documentclass{css}
%\documentclass[english]{css}

\usepackage[dvips]{graphicx}
\usepackage{latexsym}

\def\|{\verb|}

\newcommand{\cssyear}[0]{2023}
\newcommand{\cssname}[0]{CSS 2023}
\newcommand{\cssversion}[0]{2023/06/01}
\newcommand{\cssemail}[0]{css2023-office@iwsec.org}

\begin{document}

%% 本文が和文の場合，タイトル・著者名・著者所属・概要は，和文・英文共に必須．
%% If you prepare this manuscript in English, there is no need to put Japanese metadata (title, author names, affiliations, abstract, and keywords) in it.

\title{Isolation Forestを用いた\\IoT向け異常検知手法に関する考察}
\etitle{A Study on Anomaly Detection Method \\for IoT using Isolation Forest}

\affiliate{XX}{東京工業大学 情報理工学院 数理・計算科学系\\
Department of Mathematical and Computing Sciences, School of Computing, Tokyo Institute of Technology}
\affiliate{YY}{株式会社YYセキュリティ研究所\\
Security Laboratories, YY Corporation}
\paffiliate{ZZ}{国立研究開発法人ZZ研究所\\
National Institute of ZZ}

%% メールアドレスは省略可能だが，代表者のメールアドレスは必須．
%% 姓名の間は半角スペースを入れること．

\author{菅田 大輔}{Daisuke Sugata}{XX}[sugata.d.aa@m.titech.ac.jp]
\author{石井 将大}{Masahiro Ishii}{XX, YY, ZZ}[]
\author{松浦 知史}{Satoshi Matsuura}{YY}[]

%% the following is author command for english option.
%% at least one e-mail address is required.

%\author{Taro Joho}{XX}[taro.joho@xx.ac.jp]
%\author{Hanako Anzen}{XX, YY, ZZ}

\begin{abstract}
    本論文では、Isolation Forestを用いたIoT向け異常検知手法の改善を行なった。この研究の背景にIoT（Internet of Things）の普及がある。2030年には約300億台ものデバイスが利用されると予測されており、すべてのIoT機器のセキュリティ確保が重要な課題となっている。特に2016年のMirai型マルウェアによるDDoS攻撃はその必要性を浮き彫りにした。本研究は専門的なセキュリティ対策が難しい、家庭内ネットワークなどの小規模環境に着目し、軽量で高速な異常検知システムの提案を目指した。Isolation Forestは軽量で高速に動作する異常検知手法として注目されているが、これを用いた従来の方法には二つの問題が存在する。閾値を手動で設定する必要がある点と、閾値による異常判定のアルゴリズムの精度に限界がある点である。これらの課題を解決するため、異常判定をする際にロジスティック回帰を応用した判定アルゴリズムを提案する。提案手法を二つのデータセットで実験した結果、精度がそれぞれ84.4\%から91.1\%、84.6\%から94.5\%に改善したことを確認した。

\end{abstract}

%% キーワード (1--5単語) の記載は任意．

\begin{jkeyword}
Isolation Forest， IoT， IDS， 異常検知
\end{jkeyword}

\begin{eabstract}
    This paper presents an improved anomaly detection method for IoT environments using Isolation Forest. The motivation for this study lies in the widespread adoption of the Internet of Things (IoT). By 2030, it is estimated that around 30 billion devices will be in use, making the security of all IoT devices a critical issue. The necessity of this was highlighted by the 2016 DDoS attack caused by Mirai malware. This study focuses on small-scale environments, such as home networks, where implementing specialized security measures is challenging, and aims to propose a lightweight and fast anomaly detection system. Although Isolation Forest is recognized for being a lightweight and fast anomaly detection method, traditional approaches using it have two main issues: the need for manual threshold setting and limitations in the accuracy of anomaly detection algorithms based on these thresholds. To address these challenges, we propose an anomaly detection algorithm that incorporates logistic regression for decision-making. Experiments on two datasets showed that the accuracy of the proposed method improved from 84.4\% to 91.1\% and from 84.6\% to 94.5\%, respectively.
abstract

\end{eabstract}

%% the following keyword part is optional and can be omitted.

\begin{ekeyword}
Isolation Forest, IoT, IDS, Anomaly Detection
\end{ekeyword}

%% if you use english opsion, you should put your English abstract in the abstract environment.
%% eabstract is not displayed in english mode.

\maketitle

%1
\section{はじめに}

\section{研究方法}

\subsection{Isolation Forestの説明}
Isolation Forest（以下，iForest）は，外れ値検出のためのアルゴリズムである。iForestは異常データが少数であり、離れているという前提に基づいている。ランダムにデータを分割していくと、異常データは相対的に早く分離される。iForestは以下のステップで実行される。

\subsubsection*{1. データの分割}
ランダムに選んだ特徴量から、ランダムに選んだ値をもとにデータを分割する。これを一定回数繰り返し、複数のツリーを作成する。

\subsubsection*{2. 異常スコアの算出}
データがツリーの枝に到達するまでの平均パスをもとに、異常スコアを算出する。具体的な計算式は以下の通りである。

ここで、$E(h(x))$はデータ点$x$の平均パス長、$c(n)$はデータセットのサイズ$n$に依存する定数である。

\subsubsection*{3. 異常判定}
先ほど計算した異常スコアをもとに異常検知を行う。通常、トレーニングデータの異常スコアの上位10\%を閾値として設定し、それを超えたデータを異常と判定する。


\subsection{IDSの概要}
本研究では、小規模なIoT環境に適したIntrusion Detection System（IDS）の設計について検討する。具体的には、Isolation Forestを用いた異常検知手法が提案され、その有効性を評価する。

\subsection{全体の設計}
IDSの設計は以下の3つのセクションに分けられる：
\begin{enumerate}
    \item \textbf{データの前処理}：
        \begin{itemize}
            \item 入力データを適切な形式に変換する。
            \item 不必要な特徴量の削除やデータの標準化、ラベルエンコーディングを行う。
        \end{itemize}
    \item \textbf{特徴量選択}：
        \begin{itemize}
            \item 判定に重要な特徴量を選択し、過学習を防ぎ、検知精度を向上させる。
            \item Random Forestを用いて特徴量の重要度を算出し、重要な特徴量を選択する。
        \end{itemize}
    \item \textbf{攻撃の判定}：
        \begin{itemize}
            \item iforestを用いて通信が攻撃通信であるかを判定する。
            \item 特徴量の選択後、Isolation Forestで異常検知を行う。
        \end{itemize}
\end{enumerate}

\subsection{実装}
実装は以下のステップで行う：
\begin{enumerate}
    \item \textbf{データの前処理}：
        \begin{itemize}
            \item はじめに、不必要な特徴量の削除を行う。（データの標準化を行う必要なし？）Iforestに入力できるのは数値データだけなので、カテゴリカルデータを数値データに変換する。one-hotエンコーディングを用いてラベルのエンコーディングを行う。
        \end{itemize}
    \item \textbf{特徴量選択}：
        \begin{itemize}
            \item Random Forestを用いて特徴量の重要度を算出する。その後、重要度をもとに上位1割の特徴量を使用する。
        \end{itemize}
    \item \textbf{攻撃の判定}：
        \begin{itemize}
            \item 攻撃通信、正常通信のそれぞれでトレーニングされたサブシステムが、Isolation Forestによって異常検知を行う。
            \item それぞれのサブシステムの結果を２通りで組み合わせ、最終的な判定を行う。
        \end{itemize}
\end{enumerate}


\section{iForestの問題点の整理}
Isolation Forestを異常検知手法として使用する際にどのような問題があるのかを明らかにするための事前実験を行った．はじめにデモデータを使用して，iForestの挙動を確認した．その考察をもとに特徴量選択手法の提案を行なった

使用したデモデータは、(2.5, 2.5)と(-2.5, -2.5)を中心とした
正常データ群と、10から-10の範囲に一様に分布した異常データ群からなる．二次元の場合のデモデータを図\ref{fig:demodata}に示す．

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{pictures/eps/demodata.eps}
    \caption{デモデータに関する図の説明（和文）}
    \ecaption{Description of the dim\_vs\_accu figure (English).}
    \label{fig:demodata}
\end{figure}

はじめに、デモデータと特徴量数の関係を調査した．図\ref{fig:dim_vs_accu}に示すように、特徴量数が増えるにつれて、異常検知の精度が単調に向上することがわかった．また、精度ののびは増加に反比例して緩やかになっていることもわかる。ゆえに、iForestは目標とする精度に対して十分な特徴量数が存在すると言える。

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{pictures/eps/dim_vs_accu.eps}
    \caption{dim\_vs\_accuに関する図の説明（和文）}
    \ecaption{Description of the dim\_vs\_accu figure (English).}
    \label{fig:dim_vs_accu}
\end{figure}

続いて、デモデータにノイズ特徴量を含めたときの精度の悪化について調査した。パケット通信を監視して得られたデータセットの全ての特徴が、異常検知に有効なわけではない。そして、iForestは特徴量同士の重みづけを行わないため、判定に有効でない特徴量が混ざると精度が低下すると考えられる。図\ref{fig:noise_accu}に示すように、ノイズとなる特徴量が混ざると精度が低下することがわかった。また、今回の実験の場合だと、ノイズ特徴量が判定に有効な特徴量数の2倍以上になると、精度が急激に低下することがわかった。

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{pictures/eps/noise_accu.eps}
    \caption{noise\_accuに関する図の説明（和文）}
    \ecaption{Description of the noise\_accu figure (English).}
    \label{fig:noise_accu}
\end{figure}

前の実験から、データセットからノイズとなる特徴量を取り除くことが重要であると考えられる。ところで、iForestはツリーベースの異常検知手法である。そこで、同じくツリーベースのRandam Forestから特徴の重要度を算出すれば、ノイズとなる特徴量を取り除けるのではないかと考えた。図\ref{fig:select_noise}は、Random Forestで算出した特徴量の重要度を表している。このグラフは、ノイズ特徴量を判別できていることがわかる。そして、実際にノイズ特徴量を取り除いた場合の精度を調査したところ、精度は???\%から0.945\%まで向上した。この結果から、Feature Importanceによる特徴量選択手法は精度の向上に有効ではないかと考えた。

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{pictures/eps/select_noise.eps}
    \caption{select\_noiseに関する図の説明（和文）}
    \ecaption{Description of the select\_noise figure (English).}
    \label{fig:select_noise}
\end{figure}

\subsection{より効果的な判定の組み合わせ方について}
Iforestを用いた異常検知手法では、攻撃データと正常データのそれぞれでトレーニングされたサブシステムが、Isolation Forestによって異常検知を行う。最終的な判定は、これらの結果を組み合わせて行う。AbuAlgahamらの研究では、表\ref{tab:combination}のようにそれぞれの判定器の結果を組み合わせて最終的な判定を行う。

\begin{table}[tb]
    \caption{組み合わせアルゴリズム（和文）}
    \ecaption{combination algorithm (English).}
    \centering
    \footnotesize
    \begin{tabular}{lcc}
        \hline
        Normal subsystem & Attack subsystem & combination result\\
        \hline
        Normal & Anomaly & Normal \\
        Anomaly & Normal & Anomaly \\
        Normal & Normal & Anomaly \\
        Anomaly & Anomaly & unknown \\
        \hline
    \end{tabular}
    \label{tab:combination}
\end{table}

しかし、表\ref{tab:combination}のようなマッピングによる判定手法は以下の2つの問題を抱えている。
\begin{itemize}
    \item それぞれの判定器の異常スコアの閾値を手動で設定する必要があること
    \item 異常判定の境界線が直線であるため、異常スコアの分布によっては誤判定が多くなること
\end{itemize}
実際に異常スコアの分布を調査したところ、図\ref{fig:UNSW1}と図\ref{fig:NSL1}のように、異常スコアの分布が斜めになっていることがわかる。このような場合、直線的な分割では正確な判定ができない。

そこで、本研究では、異常スコアの分布によって適切な判定ができるように、異常検知の境界線を、ロジスティック回帰を用いて決定する手法を提案する。この手法では、それぞれのサブシステムの異常スコアを入力とし、ロジスティック回帰によって異常判定を行う。この手法を用いることで、1.iForestの閾値を設定する必要がない 2. 閾値による直線的な分割よりも正確な判定が行える という利点がある。

\section{結果と考察}

\subsection{比較するアルゴリズム}

本研究では、以下の2つの比較を行った。
特徴量エンジニアリングの効果の比較を行うため、特徴量選択を行わなかった場合と、Random Forestを用いた特徴量選択手法を用いた場合の結果を比較する。また、判定の組み合わせアルゴリズムの比較には、2つのサブシステムの結果をマッピングする手法と、Rogistic Regressionを用いて判定を行う手法の結果を比較した。

\begin{enumerate}
    \item \textbf{特徴量エンジニアリングの比較}：
        \begin{itemize}
            \item 特徴量選択なし
            \item Random Forestを用いた特徴量選択手法
        \end{itemize}
    \item \textbf{判定の組み合わせアルゴリズムの比較}：
        \begin{itemize}
            \item マッピングして判定
            \item Rogistic Regressionを用いて判定
        \end{itemize}
\end{enumerate}

\subsubsection{実験環境}

実験はMac Book Pro 2017 2.3GHz Intel Core i5, 8GB RAMで行った。また、実験に用いたプログラムはPython3.10.4で実装した。Isolation ForestやRandom Forestの実装には、scikit-learnのライブラリを用いた。

\subsubsection{データセット}
本実験では、以下の2つのデータセットを用いた。

\begin{enumerate}
    \item \textbf{NSL-KDD}：
        KDDCUP99の問題点を解決するために提案されたデータセットであり、データの冗長性や攻撃データの割合を調整したもの。
    \item \textbf{UNSW-NB15}：
        既存のデータセットの問題点を解決し、現代のネットワークトラフィックと低フットプリント攻撃を包括的に反映するために作成されたデータセット。
\end{enumerate}

\subsubsection{評価指標}
本研究では、以下の4つの評価指標を用いてモデルの性能を評価した。

\begin{enumerate}
    \item \textbf{Accuracy}：
        正確度を示し、予測が実際のクラスと一致する割合を示す。
    \item \textbf{Precision}：
        予測が正常と判定されたデータのうち、実際に正常であるデータの割合を示す。
    \item \textbf{Recall}：
        実際に正常であるデータのうち、正常と判定されたデータの割合を示す。
    \item \textbf{F1-score}：
        PrecisionとRecallの調和平均を示す。
\end{enumerate}

\subsection{結果}

初めに、2つのデータセットに対してトレーニングデータの異常スコアの分布を調査した。横軸は正常データで訓練されたiForestが算出した異常スコアであり、攻撃データのIForestが計算したものが縦軸である。それぞれの零点は異常スコアの閾値であり、負方向に大きいと異常スコアが高く、正方向に大きいと異常スコアが小さいことを示す。各点の色はデータのラベルを表し、赤が攻撃(1)、青が正常(0)である。

図\ref{fig:UNSW1}はデータセットUNSWの異常スコア分布であり、図\ref{fig:NSL1}はデータセットNSLの異常スコアの分布である。UNSWのデータセットでは、データが対角線方向に分布しており、
2つのサブシステムの判定が相反していることがわかる。また、正常データが右下に多く存在し、

異常スコアの分布が斜めになっていることがわかる。このような場合、表\ref{tab:combination}のような直線的な分割では正確な判定ができない。

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{pictures/eps/UNSW1.eps}
    \caption{UNSW1（和文）}
    \ecaption{Description of the collectness\_UNSW figure (English).}
    \label{fig:UNSW1}
\end{figure}

\begin{figure}[tb]
    \centering
    \includegraphics[width=\linewidth]{pictures/eps/NSL1.eps}
    \caption{NSL1（和文）}
    \ecaption{Description of the collectness\_UNSW figure (English).}
    \label{fig:NSL1}
\end{figure}

結果は以下の通りである。

\begin{table}[tb]
    \caption{UNSWでのモデルの性能評価結果（和文）}
    \ecaption{Performance evaluation results of models (English).}
    \centering
    \footnotesize
    \begin{tabular}{lcccc}
        \hline\hline
        model & accuracy & precision & recall & f1 \\
        \hline
        特徴量選択なし & 0.7506 & 0.7949 & 0.7506 & 0.7526 \\
        特徴量選択なし、ロジスティック回帰で判定 & 0.8685 &  0.8666 & 0.8685 & 0.8666 \\
        特徴量選択あり & 0.8440 & 0.9321 & 0.8440 & 0.8817 \\
        特徴量選択あり、ロジスティック回帰で判定 & 0.9112 & 0.9146 & 0.9112 & 0.9082 \\
        \hline
    \end{tabular}
    \label{tab:model_performance}
\end{table}

\begin{table}[tb]
    \caption{NSLでのモデルの性能評価結果（和文）}
    \ecaption{Performance evaluation results of models (English).}
    \centering
    \footnotesize
    \begin{tabular}{lcccc}
        \hline\hline
        model & accuracy & precision & recall & f1 \\
        \hline
        特徴量選択なし & 0.7873 & 0.8749 & 0.7873 & 0.8171 \\
        特徴量選択なし、ロジスティック回帰で判定 & - & - & - & -\\ 
        特徴量選択あり & 0.8466 & 0.9174 & 0.8466 & 0.8775 \\
        ロジスティック回帰で判定 & 0.9452 & 0.9453 & 0.9452 & 0.9452 \\
        \hline
    \end{tabular}
    \label{tab:model_performance}
\end{table}

この結果から、また、ロジスティック回帰を用いて判定を行うことで、精度が向上することがわかった。

\subsection{考察}
今回の実験から、ロジスティック回帰を応用した異常判定手法により、精度が向上することがわかった。これは、今回使用した２つのデータセットの、異常スコアの分布の境界線が斜めであり、線形な境界線でうまく分割できたためであると考えられる。

境界線が曲面であったり、データセットが混ざってしまっている場合、うまくいかない

plusAlphaでかければいいこと
モデル構築のコストの比較
・ロジスティック回帰のコストvsiforestの探索（）
の計算量（時間）を比較する

ロジスティック回帰におけるランダムサンプルしての精度の比較（調べてもいい）
サンプリングの適用範囲（データ量と精度のトレードオフ）

\section{おわりに}
おわりにを書く.

\begin{acknowledgment}
謝辞を書く.
\end{acknowledgment}

\begin{thebibliography}{10}

\end{thebibliography}

\end{document}
